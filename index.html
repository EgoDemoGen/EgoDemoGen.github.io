<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation">
  <meta name="keywords" content="DriveDreamer">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/ms_icon.png">

  <style>  
    table {  
      font-family: arial, sans-serif;  
      border-collapse: collapse;  
      width: 100%;  
    }  
      
    td, th {  
      border: 2px solid #F1F4F5;  
      text-align: left;  
      padding: 8px;  
    }  
    tr:nth-child(3n - 1) {  
      background-color: #F1F4F5;  
    }  

    tr:nth-child(3n) {  
      border: 2px solid #FFFFFF;
    }  
  </style>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="#">Yuan Xu</a><sup>1,2*</sup>,</span>
            <span class="author-block">
              <a href="#">Jiabing Yang</a><sup>1,2*</sup>,</span>
            <span class="author-block">
              <a href="#">Xiaofeng Wang</a><sup>3,4</sup>,</span>
            <span class="author-block">
              <a href="#">Yixiang Chen</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="#">Zheng Zhu</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="#">Bowen Fang</a><sup>1,2</sup>,</span>
            <br>
            <span class="author-block">
              <a href="#">Guan Huang</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="#">Xinze Chen</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="#">Yun Ye</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="#">Qiang Zhang</a><sup>5</sup>,</span>
            <span class="author-block">
              <a href="#">Peiyan Li</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="#">Xiangnan Wu</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="#">Kai Wang</a><sup>2</sup>,</span>
            <br>
            <span class="author-block">
              <a href="#">Bing Zhan</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="#">Shuo Lu</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href="#">Jing Liu</a><sup>1,2,6</sup>,</span>
            <span class="author-block">
              <a href="#">Nianfeng Liu</a><sup>1,2,6</sup>,</span>
            <span class="author-block">
              <a href="#">Yan Huang</a><sup>1,2,6</sup>,</span>
            <span class="author-block">
              <a href="#">Liang Wang</a><sup>1,2</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">UCAS<sup>1</sup>,</span>
            <span class="author-block">CASIA<sup>2</sup>,</span>
            <span class="author-block">GigaAI<sup>3</sup>,</span>
            <span class="author-block">THU<sup>4</sup>,</span>
            <span class="author-block">X-Humanoid<sup>5</sup>,</span>
            <span class="author-block">FiveAges<sup>6</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <!-- <div class="publication-links"> -->
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2309.09777.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/JeffWang987/DriveDreamer"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img id="teaser" autoplay muted loop playsinline height="100%" src="./static/images/abs.png" style="width:100%;height:100%;">
      <p  style="font-size: 16px;"> 
        DriveDreamer excels in controllable driving video generation, aligning seamlessly with text prompts and structured traffic constraints. DriveDreamer can also interact with the driving scene and predict different future driving videos, based on input driving actions. Furthermore, DriveDreamer extends its utility to anticipate future driving actions.
      </p>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning based policies perform well in robotic manipulation, but they often degrade under <em>egocentric viewpoint shifts</em> when trained from a single egocentric viewpoint. To address this issue, we present <strong>EgoDemoGen</strong>, a framework that generates <em>paired</em> novel egocentric demonstrations by retargeting actions in the novel egocentric frame and synthesizing the corresponding egocentric observation videos with proposed generative video repair model <strong>EgoViewTransfer</strong>, which is conditioned by a novel-viewpoint reprojected scene video and a robot-only video rendered from the retargeted joint actions. EgoViewTransfer is finetuned from a pretrained video generation model using self-supervised double reprojection strategy. We evaluate EgoDemoGen on both simulation (RoboTwin2.0) and real-world robot. After training with a mixture of EgoDemoGen-generated novel egocentric demonstrations and original standard egocentric demonstrations, policy success rate improves <strong>absolutely</strong> by <strong>+17.0%</strong> for standard egocentric viewpoint and by <strong>+17.7%</strong> for novel egocentric viewpoints in simulation. On real-world robot, the <strong>absolute</strong> improvements are <strong>+18.3%</strong> and <strong>+25.8%</strong>. Moreover, performance continues to improve as the proportion of EgoDemoGen-generated demonstrations increases, with diminishing returns. These results demonstrate that EgoDemoGen provides a practical route to egocentric viewpoint-robust robotic manipulation.
          </p>
        </div> 
      </div>
    </div>


  </div>
</section>


<section class="section" id="Method">
  <div class="container is-max-desktop content">
    <h2 class="title">Method</h2>
    
    <!-- Overview Section -->
    <h3 class="title is-4 has-text-centered">Overview</h3>
    <section class="hero method">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img id="overview" autoplay muted loop playsinline height="100%" src="./static/images/overview.png" style="width:100%;height:100%;">
          <p class="has-text-centered" style="font-style: italic; margin-top: 10px;">
            Framework of EgoDemoGen.
          </p>
            <p>
              <strong>Overview of EgoDemoGen.</strong> <strong>(1) Egocentric View Transform:</strong> a <em>Novel Egocentric View</em> is specified by robot base motion <span class="math inline">\((\Delta x,\ \Delta y,\ \Delta \theta)\)</span>. <strong>(2) Action Retargeting:</strong> the original joint actions <span class="math inline">\(Q\)</span> is <em>retargeted</em> into the novel robot base frame to yield a kinematically feasible joint actions <span class="math inline">\(\tilde{Q}\)</span>. <strong>(3) Novel Egocentric Observations:</strong> starting from the original observation video <span class="math inline">\(V\)</span>, we mask the robot, reproject the scene to the novel viewpoint, perform hole filling, and apply <strong>EgoViewTransfer</strong> to synthesize the coherent observations <span class="math inline">\(\tilde{V}\)</span>. <strong>(4) Novel Demonstrations & Policy Training:</strong> we obtain aligned pairs <span class="math inline">\((\tilde{V},\ \tilde{Q})\)</span> for training egocentric viewpoint-robust policies.
            </p>
        </div>
      </div>
    </section>

    <!-- EgoViewTransfer Section -->
    <h3 class="title is-4 has-text-centered">EgoViewTransfer</h3>
    <section class="hero method">
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img id="egoviewtransfer" autoplay muted loop playsinline height="100%" src="./static/images/double.png" style="width:100%;height:100%;">
          <p class="has-text-centered" style="font-style: italic; margin-top: 10px;">
            Architecture of EgoViewTransfer.
          </p>
            <p>
              <strong>EgoViewTransfer.</strong> <strong>(a) Double reprojection.</strong> It simulates artifacts and occlusions caused by viewpoint change. The double reprojected video are aligned with the original video to form input/label pairs for training. <strong>(b) Architecture of EgoViewTransfer.</strong> The model takes a degraded scene video and a robot video as conditions and generates egocentric observation videos consistent with dual inputs.
            </p>
        </div>
      </div>
    </section>
  </div>
</section>


<section class="section" id="Results">
  <div class="container is-max-desktop content">
    <h2 class="title">Results</h2>
    <section class="hero method">
    <div class="container is-max-desktop">
    <div class="hero-body">  

  <h4 class="title">1. Visualization of policy execution in the Simulation.</h4>
    <div class="container is-max-desktop">
        <img id="simulation_policy" src="./static/images/simulation_policy.png" style="width:100%;height:100%;">
        <p class="has-text-centered" style="font-style: italic; margin-top: 10px;">
          Visualization of policy execution in the Simulation. The <strong style="color: green;">green</strong> boxes denote the standard egocentric view, the <strong style="color: red;">red</strong> boxes denote the random novel egocentric view.
        </p>
    </div> 
    <br>
    <p style="margin-bottom: 30px;"></p>

	<h4 class="title">2. Visualization of policy execution in the Real World.</h4>
  <div class="container is-max-desktop">
    <div style="text-align: center;">
      <img id="realworld_policy" src="./static/images/realworld_policy.png" style="width:100%;height:100%;">
      <p class="has-text-centered" style="font-style: italic; margin-top: 10px;">
        Visualization of policy execution in the Real World. The <strong style="color: green;">green</strong> boxes denote the standard egocentric view, the <strong style="color: red;">red</strong> boxes denote the counterclockwise egocentric view, and the <strong style="color: blue;">blue</strong> boxes denote the clockwise egocentric view.
      </p>
    </div>
  </div>
  <br>
	<p style="margin-bottom: 30px;"></p>

  <h4 class="title">3. Visualization of EgoViewTransfer in Simulation.</h4>

  <div class="container is-max-desktop">
    <div style="text-align: center;">
      <img id="simulation_egoviewtransfer" src="./static/images/simulation_egoviewtransfer.png" style="width:100%;height:100%;">
      <p class="has-text-centered" style="font-style: italic; margin-top: 10px;">
        Visualization of EgoViewTransfer in Simulation. The <strong style="color: green;">green</strong> boxes denote the GT video, the <strong style="color: red;">red</strong> boxes denote the Video w/ EgoViewTransfer, and the <strong style="color: blue;">blue</strong> boxes denote the Video w/o EgoViewTransfer (Naive Composition).
      </p>
    </div>
  </div>
  <br>
	<p style="margin-bottom: 30px;"></p>

	<h4 class="title">4. Visualization of EgoViewTransfer in Real World.</h4>

  <div class="container is-max-desktop">
    <div style="text-align: center;">
      <img id="realworld_egoviewtransfer" src="./static/images/realworld_egoviewtransfer.png" style="width:100%;height:100%;">
      <p class="has-text-centered" style="font-style: italic; margin-top: 10px;">
        Visualization of EgoViewTransfer in Real World. The <strong style="color: red;">red</strong> boxes denote the Video w/ EgoViewTransfer, the <strong style="color: blue;">blue</strong> boxes denote the Video w/o EgoViewTransfer (Naive Composition).
      </p>
    </div>
  </div>

  </div></div></section>
  </div>
</section>

	
	
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <p> If you use our work in your research, please cite: </p>
    <pre><code>@article{xu2025egodemogen,
  title={EgoDemoGen: Novel Egocentric Demonstration Generation Enables Viewpoint-Robust Manipulation},
  author={Xu, Yuan and Yang, Jiabing and Wang, Xiaofeng and Chen, Yixiang and Zhu, Zheng and Fang, Bowen and Huang, Guan and Chen, Xinze and Ye, Yun and Zhang, Qiang and Li, Peiyan and Wu, Xiangnan and Wang, Kai and Zhan, Bing and Lu, Shuo and Liu, Jing and Liu, Nianfeng and Huang, Yan and Wang, Liang},
  journal={arXiv preprint arXiv:2509.22578},
  year={2025}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/JeffWang987/DriveDreamer" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            Website adapted from the following <a href="https://github.com/nerfies/nerfies.github.io">template</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
